{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision.models import resnet50\n",
    "import csv\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"G:\\\\Yehmh\\\\DNDF\\\\202309_DNDF\\\\species\\\\5m_5m\"\n",
    "model_path = 'G:/Yehmh/_model/0411_DNDF_resnet_74.pth'\n",
    "\n",
    "X = []  # Features\n",
    "y = []  # Labels\n",
    "\n",
    "\n",
    "for folder in os.listdir(data_dir):\n",
    "    if os.path.isdir(os.path.join(data_dir, folder)):  # Check if it's a directory\n",
    "        species = folder  # Assuming folder name is the species label\n",
    "        y.append(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acac_au' 'Bisc_ja' 'Brou_pa' 'Call_fo' 'Cinn_bu' 'Cinn_ca' 'Elae_sy'\n",
      " 'Frax_gr' 'Koel_el' 'Liqu_fo' 'Luec_le' 'Mach_zu' 'Magn_co' 'Pter_in'\n",
      " 'Quer_gl' 'Zelk_se' '_not_tree']\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.resnet = resnet50(pretrained=True)  # Load pretrained ResNet-50\n",
    "        # Replace the last fully connected layer with a new one\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Function to extract coordinates from TIF files\n",
    "def extract_coordinates(tif_file):\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        crs = src.crs\n",
    "        bounds = src.bounds\n",
    "        center_x = (bounds.left + bounds.right) / 2\n",
    "        center_y = (bounds.top + bounds.bottom) / 2\n",
    "        return crs, (center_x, center_y)\n",
    "\n",
    "def classify_and_write(unknown_photos_dir, output_csv_path):\n",
    "\n",
    "    # Initialize lists to store unknown photo paths, coordinates, and predictions\n",
    "    unknown_photos = []\n",
    "    unknown_coordinates = []\n",
    "\n",
    "    # Iterate over unknown TIF files\n",
    "    for filename in os.listdir(unknown_photos_dir):\n",
    "        if filename.endswith('.tif'):\n",
    "            tif_file = os.path.join(unknown_photos_dir, filename)\n",
    "            \n",
    "            # Extract coordinates\n",
    "            crs, coordinates = extract_coordinates(tif_file)\n",
    "            \n",
    "            # Append to the list\n",
    "            unknown_photos.append(tif_file)\n",
    "            unknown_coordinates.append((filename, crs, coordinates))\n",
    "\n",
    "    # Now you have a list of unknown photo paths (unknown_photos) and corresponding coordinates (unknown_coordinates)\n",
    "\n",
    "    # Define a function to classify with threshold\n",
    "    def classify_with_threshold(probabilities, threshold):\n",
    "        max_prob, max_index = torch.max(probabilities, dim=1)\n",
    "        if max_prob.item() < threshold:\n",
    "            return \"unknown\"\n",
    "        else:\n",
    "            predicted_label = label_encoder.classes_[max_index.item()]\n",
    "            return predicted_label  # Return the index of the class with the maximum probability\n",
    "\n",
    "\n",
    "    # Load the trained model\n",
    "    model = ResNet50(num_classes=len(label_encoder.classes_))\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Make predictions on the unknown photos\n",
    "    predictions = []\n",
    "    for photo_path in unknown_photos:\n",
    "        # Load and preprocess the image\n",
    "        image = cv2.imread(photo_path)\n",
    "        image = cv2.resize(image, (64, 64))  # Resize image if necessary\n",
    "        image = transform(image)\n",
    "        image = image.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            probabilities = nn.functional.softmax(output, dim=1)  # Apply softmax to get probabilities\n",
    "            classification = classify_with_threshold(probabilities, threshold=0.7)  # Adjust threshold as needed\n",
    "            predictions.append(classification)\n",
    "\n",
    "    # Now you have the predictions for each unknown photo in the list 'predictions'\n",
    "    # You can proceed to visualize the results on a map using the coordinates\n",
    "    with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Filename', 'Latitude', 'Longitude', 'Predicted Species'])  # Write header\n",
    "        for coord, label in zip(unknown_coordinates, predictions):\n",
    "            filename, crs, (latitude, longitude) = coord\n",
    "            writer.writerow([filename, latitude, longitude, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list = [69, 70, 71, 75, 76, 78, 79, 82]\n",
    "# # list = [76, 78, 79, 82]\n",
    "# # list = [78]\n",
    "\n",
    "# for i in list:\n",
    "#     unknown_photos_dir = f'D:\\\\Yehmh\\\\test_py\\\\202301\\\\P000{i}\\\\5m_5m'\n",
    "#     output_csv_path = f'D:/Yehmh/test_py/202301/P000{i}_resnet_prob_2.csv'\n",
    "    \n",
    "#     classify_and_write(unknown_photos_dir, output_csv_path)\n",
    "    \n",
    "#     print(i, \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CIRES\\anaconda3\\envs\\test\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\CIRES\\anaconda3\\envs\\test\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\001\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\002\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\003\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\004\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\005\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\006\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\007\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\008\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\009\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\010\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\011\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\012\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\013\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\014\\5m_5m  done\n",
      "G:\\Yehmh\\DNDF\\202309_DNDF\\pix4d file\\015\\5m_5m  done\n"
     ]
    }
   ],
   "source": [
    "folder_paths = []\n",
    "for i in range(1, 10):\n",
    "    folder_paths.append(f\"G:\\\\Yehmh\\\\DNDF\\\\202309_DNDF\\\\pix4d file\\\\00{i}\\\\5m_5m\")\n",
    "for i in range(10, 16):\n",
    "    folder_paths.append(f\"G:\\\\Yehmh\\\\DNDF\\\\202309_DNDF\\\\pix4d file\\\\0{i}\\\\5m_5m\")\n",
    "\n",
    "i = 1\n",
    "for folder_path in folder_paths:\n",
    "    unknown_folder_path = folder_path\n",
    "    output_csv_path = f'G:\\\\Yehmh\\\\DNDF\\\\202309_DNDF\\\\results\\\\{i}_0411_resnet.csv'\n",
    "    i = i + 1\n",
    "\n",
    "    classify_and_write(unknown_folder_path, output_csv_path)\n",
    "    print(folder_path, \" done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
