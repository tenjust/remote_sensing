{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder T1S1 does not have a corresponding species label.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder T1S2 does not have a corresponding species label.\n"
     ]
    }
   ],
   "source": [
    "species_mapping = pd.read_csv(\"traps_main_species_twd97.csv\")\n",
    "\n",
    "data_dir = 'D:/Yehmh/test_py/202301/P00074_transect_1/1m_1m/known'\n",
    "Folder_names = \"T1S\"\n",
    "image_size = 34\n",
    "\n",
    "X = []  # Features\n",
    "y = []  # Labels\n",
    "\n",
    "for folder in os.listdir(data_dir):\n",
    "    if folder.startswith(Folder_names):\n",
    "        species_info = species_mapping.loc[species_mapping[\"Plot\"] == folder]\n",
    "        if not species_info.empty and not pd.isna(species_info[\"SpeciesID\"].values[0]):\n",
    "            species = species_info[\"SpeciesID\"].values[0]\n",
    "            for file in os.listdir(os.path.join(data_dir, folder)):\n",
    "                if file.endswith(\".tif\"):\n",
    "                    image_path = os.path.join(data_dir, folder, file)\n",
    "                    image = cv2.imread(image_path)                \n",
    "                    # image = cv2.resize(image, (image_size, image_size))  # Resize image if necessary\n",
    "                    # image = cv2.resize(image, (64, 64))  # Resize image if necessary\n",
    "                    X.append(image)\n",
    "                    y.append(species)\n",
    "        else:\n",
    "            print(f\"Folder {folder} does not have a corresponding species label.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 5. 7.]\n",
      "[3 3 3 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define transformations and create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image data\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
    "test_dataset = CustomDataset(X_test, y_test, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_loader is created with shuffle=False. \n",
    "# Ensures that the evaluation process remains consistent across different evaluations \n",
    "# and that the model is tested on the same data distribution every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)     # (in_channels (rgb), out_channels, filter_num, stride, padding), default stride = 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        # Define the fully connected layers\n",
    "        # self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass through the network\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        # x = x.view(-1, 64 * 16 * 16)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initialize model. loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes=len(label_encoder.classes_))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, laels):\n",
    "    pred = torch.max(prediction.data, 1)[1]\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1590547561645508\n",
      "Epoch [2/10], Loss: 1.0803948640823364\n",
      "Epoch [3/10], Loss: 0.8649986982345581\n",
      "Epoch [4/10], Loss: 1.1307172775268555\n",
      "Epoch [5/10], Loss: 0.8650143146514893\n",
      "Epoch [6/10], Loss: 1.1389328241348267\n",
      "Epoch [7/10], Loss: 0.7979801893234253\n",
      "Epoch [8/10], Loss: 0.8825727701187134\n",
      "Epoch [9/10], Loss: 0.5664574503898621\n",
      "Epoch [10/10], Loss: 1.3208736181259155\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        # print(\"Batch Shape - Images:\", images.shape)\n",
    "        # print(\"Batch Shape - Labels:\", labels.shape)\n",
    "\n",
    "        optimizer.zero_grad()   # Zero the gradient\n",
    "        outputs = model(images) # Forward pass: computer predicted outputs\n",
    "        # print(outputs.shape)\n",
    "        loss = criterion(outputs, labels) # Compute the loss\n",
    "        loss.backward()     # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        optimizer.step()    # Update the model parameters based on the gradients\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.27%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuracy: {:.2f}%'.format(100 * accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
